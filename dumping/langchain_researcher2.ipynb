{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: torchvision in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (0.17.2+cu121)\n",
      "Requirement already satisfied: torchaudio in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: filelock in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: google-api-python-client in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (2.125.0)\n",
      "Requirement already satisfied: langchain in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (0.1.14)\n",
      "Requirement already satisfied: anthropic in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: transformers in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-python-client) (2.18.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (0.0.31)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (0.1.40)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (0.1.40)\n",
      "Requirement already satisfied: numpy<2,>=1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anthropic) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: sniffio in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anthropic) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: filelock in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: certifi in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: colorama in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in k:\\binx\\ai-researcher\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Generated 7 subtopics for research topic 'bananass':\n",
      "- Generate a list of 5-10 relevant subtopics for the following research topic: bananass\n",
      "- 1. Nutritional benefits of bananas: vitamins, minerals, and fiber content\n",
      "- 2. Banana farming and production: methods, challenges, and sustainability\n",
      "- 3. Banana varieties and their unique characteristics\n",
      "- 4. Banana ripening and storage: techniques and technologies\n",
      "- 5. Banana recipes and culinary uses: desserts, smoothies, and savory dishes\n",
      "- 6. Banana peel uses: health benefits, composting, and\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'HumanMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 60\u001b[0m\n\u001b[0;32m     54\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a 2-3 paragraph research report on the subtopic \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m based on the following information:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     56\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39mprompt),\n\u001b[0;32m     57\u001b[0m     AIMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     58\u001b[0m     SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that writes research reports.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m ]\n\u001b[1;32m---> 60\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mChatAnthropic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-haiku-20240307\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     61\u001b[0m subtopic_reports[subtopic] \u001b[38;5;241m=\u001b[39m report\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResearch report for subtopic \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mk:\\Binx\\ai-researcher\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:415\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    414\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    416\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    417\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    419\u001b[0m ]\n\u001b[0;32m    420\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mk:\\Binx\\ai-researcher\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:405\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 405\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    406\u001b[0m                 m,\n\u001b[0;32m    407\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    408\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    409\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    410\u001b[0m             )\n\u001b[0;32m    411\u001b[0m         )\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mk:\\Binx\\ai-researcher\\.venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 624\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    625\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    626\u001b[0m         )\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mk:\\Binx\\ai-researcher\\.venv\\lib\\site-packages\\langchain_community\\chat_models\\anthropic.py:188\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[0;32m    185\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m--> 188\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_messages_to_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_params,\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    195\u001b[0m }\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop:\n",
      "File \u001b[1;32mk:\\Binx\\ai-researcher\\.venv\\lib\\site-packages\\langchain_community\\chat_models\\anthropic.py:131\u001b[0m, in \u001b[0;36mChatAnthropic._convert_messages_to_prompt\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAI_PROMPT:\n\u001b[0;32m    130\u001b[0m     prompt_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAI_PROMPT\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convert_messages_to_prompt_anthropic(messages\u001b[38;5;241m=\u001b[39mmessages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_params)\n",
      "File \u001b[1;32mk:\\Binx\\ai-researcher\\.venv\\lib\\site-packages\\langchain_community\\chat_models\\anthropic.py:62\u001b[0m, in \u001b[0;36mconvert_messages_to_prompt_anthropic\u001b[1;34m(messages, human_prompt, ai_prompt)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format a list of messages into a full prompt for the Anthropic model\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    messages (List[BaseMessage]): List of BaseMessage to combine.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    str: Combined string with necessary human_prompt and ai_prompt tags.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m messages \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# don't mutate the original list\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, AIMessage):\n\u001b[0;32m     63\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend(AIMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     65\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     66\u001b[0m     _convert_one_message_to_text(message, human_prompt, ai_prompt)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[0;32m     68\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'HumanMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip3 install google-api-python-client langchain anthropic transformers\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_SEARCH\")  # Replace with your Google Search API key\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")  # Replace with your Custom Search Engine ID\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")  # Set the Anthropic API key as an environment variable\n",
    "\n",
    "# Set the HuggingFaceHub API token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Prompt user for research topic\n",
    "research_topic = input(\"Enter the research topic: \")\n",
    "\n",
    "# Generate subtopics using HuggingFace model\n",
    "subtopic_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Generate a list of 5-10 relevant subtopics for the following research topic: {topic}\"\n",
    ")\n",
    "subtopic_chain = LLMChain(\n",
    "    llm=HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", model_kwargs={\"temperature\":0.1}),\n",
    "    prompt=subtopic_prompt\n",
    ")\n",
    "subtopics = subtopic_chain.run(research_topic).split(\"\\n\")\n",
    "subtopics = [s.strip() for s in subtopics if s.strip()]\n",
    "print(f\"Generated {len(subtopics)} subtopics for research topic '{research_topic}':\")\n",
    "for s in subtopics:\n",
    "    print(f\"- {s}\")\n",
    "\n",
    "# Create search queries for each subtopic\n",
    "search_queries = []\n",
    "for subtopic in subtopics:\n",
    "    query = f\"{research_topic}, {subtopic}\"\n",
    "    search_queries.append(query)\n",
    "\n",
    "# Run search queries to gather information\n",
    "search = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n",
    "subtopic_info = {}\n",
    "for i, query in enumerate(search_queries):\n",
    "    results = search.run(query)\n",
    "    subtopic_info[subtopics[i]] = \" \".join(results[:3])\n",
    "\n",
    "# Generate subtopic research reports\n",
    "subtopic_reports = {}\n",
    "for subtopic, info in subtopic_info.items():\n",
    "    prompt = f\"Write a 2-3 paragraph research report on the subtopic '{subtopic}' based on the following information:\\n{info}\"\n",
    "    messages = [\n",
    "        HumanMessage(content=prompt),\n",
    "        AIMessage(content=\"\"),\n",
    "        SystemMessage(content=\"You are a helpful assistant that writes research reports.\")\n",
    "    ]\n",
    "    report = ChatAnthropic(model=\"claude-3-haiku-20240307\").generate(messages).generations[0].text\n",
    "    subtopic_reports[subtopic] = report\n",
    "    print(f\"Research report for subtopic '{subtopic}':\")\n",
    "    print(report)\n",
    "    print()\n",
    "\n",
    "# Combine subtopic reports into final comprehensive report\n",
    "subtopic_report_text = \"\\n\".join(subtopic_reports.values())\n",
    "final_prompt = f\"Analyze and combine the following subtopic research reports into a single comprehensive report on the topic '{research_topic}':\\n{subtopic_report_text}\"\n",
    "final_messages = [\n",
    "    HumanMessage(content=final_prompt),\n",
    "    AIMessage(content=\"\"),\n",
    "    SystemMessage(content=\"You are a helpful assistant that writes comprehensive research reports.\")\n",
    "]\n",
    "final_report = ChatAnthropic(model=\"claude-3-haiku-20240307\").generate(final_messages).generations[0].text\n",
    "print(f\"Final Comprehensive Research Report on '{research_topic}':\")\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
